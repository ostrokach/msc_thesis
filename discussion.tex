% !TEX root = msc_thesis.tex

\chapter{Discussion} \label{ch:discussion}

The primary objective of this project was to extend ELASPIC and make it possible to predict the effect of mutations on protein stability and protein-protein interaction affinity on a genome-wide scale. We were able to meet this objective with a reasonable amount of success. We implemented ELASPIC as an easy to install and fully automated pipeline, which can scale from a single mutation in a user-provided PDB structure to hundreds of thousands of mutation affecting most proteins in the genome. ELASPIC can now be used as part of a pipeline for annotating variants discovered through high-throughput sequencing, since evaluating individual mutations can be done in minutes once the Provean supporting sets and homology models have been precalculated (see Section \ref{sec:precalculated_data}). With the work of Daniel Witvliet \textit{et al.} \cite{witvliet_elaspic_2016}, ELASPIC was also made accessible to the wider scientific community through a webserver.

The secondary objective of this project was to explore different approaches for using structural information in order to make more accurate and informative predictions regarding the phenotypic effect of mutations. We met the second objective with much less success than the first. Provean is better able to predict whether or not a mutation is involved in disease than ELASPIC, as measured by the performance of the two tools on the validation and the test subsets of the Humsavar, ClinVar and COSMIC datasets (see Figures \ref{fig:core_validation} and \ref{fig:interface_validation}). While we found that mutations falling inside protein-protein interaction interfaces are more likely to be associated with disease, this may be an artifact of the fact that interfaces involved in disease are more likely to be studied to have a structural template of the interaction in the PDB. We found no evidence that ``edgetic mutations'' or mutations which affect only one of multiple interactions mediated by a protein, are more likely to be deleterious than mutations that destroy all interactions, as was reported by Sahni \textit{et al.} \cite{sahni_widespread_2015}.

We could leverage kinetic models of cell metabolism \cite{bordbar_personalized_2015} or cell growth and replication \cite{karr_whole-cell_2012} and use ELASPIC to predict the effect of mutations on the corresponding phenotypes. However, even in the setting of kinetic models, the $\Delta \Delta G$ predicted by ELASPIC may not be more informative than a deleteriousness score predicted by Provean or another sequence-based tool.

the Provean score, again, may be a better predictor of whether or not a given mutation is going to disrupt the function of a protein than ELASPIC $\Delta \Delta G$.

There have been attempts in creating a full-scale kinetic model of the cell.

Personalized Whole-Cell Kinetic Models of Metabolism for Discovery in Genomics and Pharmacodynamics

We could use ELASPIC as part of a whole cell model

One approach would be to use ELASPIC in combination with kinetic midelling of the entire cell or specific pathways in the cell \cite{karr_whole-cell_2012}.

ELASPIC could be used as part of a whole-cell kinetic model \cite{karr_whole-cell_2012} to predict hte effect of mutations on the cell phenotype.
However, even in this case

At the outset of the project, we anticipated that analyzing the structural impact of mutations would allow us to predict not only whether or not a mutation is going to be deleterious but why it is going to be deleterious. To our knowledge, this is the first study comparing the impact of mutations on protein stability and protein-protein interaction affinity with mutation deleteriousness on a genome-wide scale. However, the amount of useful information that we could extract from the

Do not want to make a thermodynamic model of the cell. Provean still performs better in predicting whether or not a mutation is going to be deleterious, and we could not find features that would allow us to improve on this.

We did find that mutaitons that fall inside a protein-protein interface are more likely to be disease-causing than other mutations, but in order to predict whether or not a mutation falls inside a protein-protein interface we only need homology models of all proteins and protein-protein interactions in the genome. Furthermore, this observation could at least in part be

While this was not anticipated at the beginning of this project, we found that mutation deleteriousness is highly This objective was met with a reasonable amount of success. We made changes that allow ELASPIC to be run a. Two main factors limit the accuracy and the generalizability of ELASPIC. First, training datasets for both the core and interface predictors are limited in their accuracy and are biased in the types of mutations that they contain. Second, most features that we calculate do not appear to be very informative. In Section \ref{sec:more_data}, we describe an approach that we could take to generate more features. In Section \label{sec:better_features} we describe an approach that we could take to learn better features.

A more promising outcome of ELASPIC is in its performance on the. In the set of features selected through feature elimination, there are both sequence-based features and structure-based features. The most important sequence-based feature is the Provean score. Results of feature elimination support the view that electrostatics, van der Waals forces and entropy are the main forces determining the effect of mutations, as proposed by Benedix \textit{et al.} in the Concoord/Poisson-Boltzmann surface area model (Equation \ref{eq:benedix_et_al}).

\begin{equation} \label{eq:benedix_et_al}
    \Delta G_{CC/PBSA} = \Delta G_{electrostatic} + \Delta G_{van\ der\ Waals} + \Delta G_{entropy}
\end{equation}



\section{Adding support for multi-residue mutations} \label{sec:more_data}

ELASPIC can easily be extended to calculate the $\Delta \Delta G$ for mutations involving multiple amino acids. The main problem that would have to be solved

The tricky part is that the number of features changes with the number of amino acids that are mutated. We could address this by treating a mutation affecting multiple amino acids as a set of single amino acid mutations. For example, we could use the following recursive strategy:

% \vspace{-\topsep}
\begin{itemize}
	\itemsep0em
    \item Introduce each of the single amino acid mutations, one at a time.
    \item Select the single amino acid mutation with the most stabilizing effect.
    \item Repeat for the remaining mutations, using the structure containing the mutation selected in Step 2.
\end{itemize}

About one third on mutations in the Protherm and Skempi databases affect multiple amino acids. We could include those mutations in the training set by dividing them into single amino acid mutations and assigning to them a $\Delta \Delta G$ proportional to their contribution to the overall mutation score, as determined by the multiple amino acid substitution version of ELASPIC. This would require ``bootstrapping'' the ELASPIC predictor using single amin acid mutations, using the ``bootstrapped'' predictor to approximate the contribution of single amino acid mutaitons to the $\Delta \Delta G$ affecting mulitple amino acids, adding those mutations to the training set, and repeating.

In the case of the ELASPIC core predictor, we could create a dataset of multiple amino acid polymorphisms (MAAMs) from a thermophilic bacterium and it's closest non-thermophilic relative (maybe such a database already exists?). Cross-validate ELASPIC making sure that we predict those MAAMs to be stabilizing. Incorporate those MAAMs into our training set, weighting them accordingly.

In the case of the ELASPIC interface predictor, we could construct a dataset from phage-display read counts, and cross-validate ELASPIC while keeping track of its performance on phage display counts. Could then recursively incorporate the phage display data into the training set, weighting it by how well the ELASPIC predictor does on those mutations, as determined through cross-validation.

It is likely that the performance of the ELASPIC predictor would be lower for mutations affecting multiple amino acids than for mutations affecting a single amino acids, as the former is more likely to induce changes in the conformation of the protein that are not modelled by ELASPIC. This drop in performance could in-part be ameliorated by including a backbone relaxation step between each mutation, using molecular dynamics \cite{abraham_gromacs:_2015}, Rosetta Backrub \cite{smith_predicting_2011}, or other algorithms \cite{sun_protein_2016}.

If the ELASPIC predictor can achieve reasonable results for mutations affecting multiple amino acids, it could be used ``in reverse'' to design protein domains with increased stability and protein interfaces with increased affinity.



\section{Multitask learning of mutation deleteriousness and energetic effects} \label{sec:better_features}

In this work, we attempted to improve the generalizability of ELASPIC core and interface predictors by keeping track of their performance on mutation deleteriousness datasets throughout cross-validation and feature elimination (Figures \ref{fig:gridsearch_core}, \ref{fig:gridsearch_interface}, \ref{fig:feature_elimination_core} and \ref{fig:feature_elimination_interface}). While this approach allows us to discard predictors that overfit the training set, it does not improve the accuracy of any individual predictor.

One way to improve overall accuracy of the predictors would be to leverage information contained in mutation deleteriousness datasets to discover better and more useful features. Mutation deleteriousness datasets are much larger than the $\Delta \Delta G$ datasets, and they may allow sequential and structural features to ``mix'' in a more general environment, and produce combined features that are less noisy and better correlated with the actual effect of mutations.

We could learn those features by first training a boosted decision tree algorithm to predict mutation deleteriousness, and then use the output of those trees as input to a logistic regression model trained to predict mutation $\Delta \Delta G$ (Figure \ref{fig:multitask_learning}). The resulting predictor should not only have better accuracy, but also have a better ability to extrapolate than the currently-used gradient boosted regressor algorithm, which never predicts values that are higher or lower than the maximum or minimum value observed in the training set.

\begin{figure}[tb]
	\centering
	\includegraphics[width=0.8\textwidth]{static/elaspic/multitask_learning.pdf}
	\caption[Multitask learning of mutation deleteriousness and $\Delta \Delta G$.]{
		Multitask learning of mutation deleteriousness and $\Delta \Delta G$.
        The figure is adapted from He \textit{et al.} \cite{he_practical_2014}, where it is used to describe an algorithm that couples boosted decision trees and linear regression to predict add click-trough rate. Boosted decision trees are used to learn a feature ``manifold'' that is provided as input to the linear classifier, which in turn makes the final predictions. \\
        We propose to use a similar design, but train boosted decision trees to predict mutation deleteriousness, and fit a linear regressor to predict mutation $\Delta \Delta G$. We anticipate that the large training set of benign and deleterious mutations would allow the boosted decision tree algorithm to learn useful and generalizable features.
	}
	\label{fig:multitask_learning}
\end{figure}
